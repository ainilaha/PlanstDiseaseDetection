{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data procecessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "width = 256\n",
    "hight = 256\n",
    "train_path = \"D:/Projects/crowdai_train/train\"\n",
    "val_path = \"D:/Projects/crowdai_train/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=40,\n",
    "        fill_mode='nearest',\n",
    "        horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20837 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(width,hight),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1080 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=(width,hight),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "resnet50 = ResNet50(include_top=False,input_shape=(width,hight,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalizationV1) (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet50)\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(38, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "135/135 [==============================] - 7s 49ms/step - loss: 3.6416 - categorical_accuracy: 0.0065\n",
      "2605/2605 [==============================] - 471s 181ms/step - loss: 1.6225 - categorical_accuracy: 0.5480 - val_loss: 3.6416 - val_categorical_accuracy: 0.0065\n",
      "Epoch 2/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7582 - categorical_accuracy: 0.0093\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.7701 - categorical_accuracy: 0.7613 - val_loss: 3.7582 - val_categorical_accuracy: 0.0093\n",
      "Epoch 3/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6461 - categorical_accuracy: 0.0093\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.5411 - categorical_accuracy: 0.8266 - val_loss: 3.6461 - val_categorical_accuracy: 0.0093\n",
      "Epoch 4/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6542 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.4328 - categorical_accuracy: 0.8631 - val_loss: 3.6542 - val_categorical_accuracy: 0.0046\n",
      "Epoch 5/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6557 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.3883 - categorical_accuracy: 0.8756 - val_loss: 3.6557 - val_categorical_accuracy: 0.0046\n",
      "Epoch 6/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6566 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.3470 - categorical_accuracy: 0.8869 - val_loss: 3.6566 - val_categorical_accuracy: 0.0046\n",
      "Epoch 7/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6544 - categorical_accuracy: 0.0056\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.2965 - categorical_accuracy: 0.9041 - val_loss: 3.6544 - val_categorical_accuracy: 0.0056\n",
      "Epoch 8/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6560 - categorical_accuracy: 0.0065\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.2879 - categorical_accuracy: 0.9065 - val_loss: 3.6560 - val_categorical_accuracy: 0.0065\n",
      "Epoch 9/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6624 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.2590 - categorical_accuracy: 0.9161 - val_loss: 3.6624 - val_categorical_accuracy: 0.0046\n",
      "Epoch 10/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6608 - categorical_accuracy: 0.0056\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.2695 - categorical_accuracy: 0.9126 - val_loss: 3.6608 - val_categorical_accuracy: 0.0056\n",
      "Epoch 11/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6610 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.2376 - categorical_accuracy: 0.9223 - val_loss: 3.6610 - val_categorical_accuracy: 0.0074\n",
      "Epoch 12/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6661 - categorical_accuracy: 0.0065\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.2194 - categorical_accuracy: 0.9289 - val_loss: 3.6661 - val_categorical_accuracy: 0.0065\n",
      "Epoch 13/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6700 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.2240 - categorical_accuracy: 0.9282 - val_loss: 3.6700 - val_categorical_accuracy: 0.0046\n",
      "Epoch 14/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6669 - categorical_accuracy: 0.0056\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1991 - categorical_accuracy: 0.9362 - val_loss: 3.6669 - val_categorical_accuracy: 0.0056\n",
      "Epoch 15/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6696 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1946 - categorical_accuracy: 0.9385 - val_loss: 3.6696 - val_categorical_accuracy: 0.0046\n",
      "Epoch 16/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6723 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.2001 - categorical_accuracy: 0.9334 - val_loss: 3.6723 - val_categorical_accuracy: 0.0046\n",
      "Epoch 17/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6755 - categorical_accuracy: 0.0046 \n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1868 - categorical_accuracy: 0.9388 - val_loss: 3.6755 - val_categorical_accuracy: 0.0046\n",
      "Epoch 18/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6760 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1730 - categorical_accuracy: 0.9430 - val_loss: 3.6760 - val_categorical_accuracy: 0.0046\n",
      "Epoch 19/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6774 - categorical_accuracy: 0.0056\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1803 - categorical_accuracy: 0.9414 - val_loss: 3.6774 - val_categorical_accuracy: 0.0056\n",
      "Epoch 20/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6791 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1514 - categorical_accuracy: 0.9508 - val_loss: 3.6791 - val_categorical_accuracy: 0.0046\n",
      "Epoch 21/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6807 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1555 - categorical_accuracy: 0.9475 - val_loss: 3.6807 - val_categorical_accuracy: 0.0046\n",
      "Epoch 22/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6805 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1618 - categorical_accuracy: 0.9462 - val_loss: 3.6805 - val_categorical_accuracy: 0.0046\n",
      "Epoch 23/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6821 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1531 - categorical_accuracy: 0.9506 - val_loss: 3.6821 - val_categorical_accuracy: 0.0046\n",
      "Epoch 24/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6856 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1536 - categorical_accuracy: 0.9515 - val_loss: 3.6856 - val_categorical_accuracy: 0.0046\n",
      "Epoch 25/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6873 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1379 - categorical_accuracy: 0.9535 - val_loss: 3.6873 - val_categorical_accuracy: 0.0046\n",
      "Epoch 26/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6895 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1359 - categorical_accuracy: 0.9561 - val_loss: 3.6895 - val_categorical_accuracy: 0.0046\n",
      "Epoch 27/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6919 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1425 - categorical_accuracy: 0.9538 - val_loss: 3.6919 - val_categorical_accuracy: 0.0046\n",
      "Epoch 28/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6925 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1346 - categorical_accuracy: 0.9551 - val_loss: 3.6925 - val_categorical_accuracy: 0.0046\n",
      "Epoch 29/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6951 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.1317 - categorical_accuracy: 0.9576 - val_loss: 3.6951 - val_categorical_accuracy: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6979 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1489 - categorical_accuracy: 0.9535 - val_loss: 3.6979 - val_categorical_accuracy: 0.0046\n",
      "Epoch 31/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7000 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1288 - categorical_accuracy: 0.9597 - val_loss: 3.7000 - val_categorical_accuracy: 0.0046\n",
      "Epoch 32/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.6981 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1175 - categorical_accuracy: 0.9602 - val_loss: 3.6981 - val_categorical_accuracy: 0.0046\n",
      "Epoch 33/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6995 - categorical_accuracy: 0.0046\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1319 - categorical_accuracy: 0.9582 - val_loss: 3.6995 - val_categorical_accuracy: 0.0046\n",
      "Epoch 34/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.6995 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1289 - categorical_accuracy: 0.9596 - val_loss: 3.6995 - val_categorical_accuracy: 0.0074\n",
      "Epoch 35/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7004 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.1282 - categorical_accuracy: 0.9577 - val_loss: 3.7004 - val_categorical_accuracy: 0.0074\n",
      "Epoch 36/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7010 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1133 - categorical_accuracy: 0.9641 - val_loss: 3.7010 - val_categorical_accuracy: 0.0074\n",
      "Epoch 37/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7041 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.1159 - categorical_accuracy: 0.9617 - val_loss: 3.7041 - val_categorical_accuracy: 0.0074\n",
      "Epoch 38/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7036 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1407 - categorical_accuracy: 0.9554 - val_loss: 3.7036 - val_categorical_accuracy: 0.0074\n",
      "Epoch 39/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7057 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 469s 180ms/step - loss: 0.1332 - categorical_accuracy: 0.9578 - val_loss: 3.7057 - val_categorical_accuracy: 0.0074\n",
      "Epoch 40/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7051 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1242 - categorical_accuracy: 0.9618 - val_loss: 3.7051 - val_categorical_accuracy: 0.0074\n",
      "Epoch 41/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7086 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1129 - categorical_accuracy: 0.9635 - val_loss: 3.7086 - val_categorical_accuracy: 0.0074\n",
      "Epoch 42/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7110 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1070 - categorical_accuracy: 0.9664 - val_loss: 3.7110 - val_categorical_accuracy: 0.0074\n",
      "Epoch 43/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7143 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1257 - categorical_accuracy: 0.9605 - val_loss: 3.7143 - val_categorical_accuracy: 0.0074\n",
      "Epoch 44/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7116 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1517 - categorical_accuracy: 0.9523 - val_loss: 3.7116 - val_categorical_accuracy: 0.0074\n",
      "Epoch 45/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7133 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1119 - categorical_accuracy: 0.9631 - val_loss: 3.7133 - val_categorical_accuracy: 0.0074\n",
      "Epoch 46/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7130 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1168 - categorical_accuracy: 0.9626 - val_loss: 3.7130 - val_categorical_accuracy: 0.0074\n",
      "Epoch 47/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7186 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1231 - categorical_accuracy: 0.9628 - val_loss: 3.7186 - val_categorical_accuracy: 0.0074\n",
      "Epoch 48/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7199 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1193 - categorical_accuracy: 0.9618 - val_loss: 3.7199 - val_categorical_accuracy: 0.0074\n",
      "Epoch 49/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7209 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1128 - categorical_accuracy: 0.9646 - val_loss: 3.7209 - val_categorical_accuracy: 0.0074\n",
      "Epoch 50/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7189 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1084 - categorical_accuracy: 0.9664 - val_loss: 3.7189 - val_categorical_accuracy: 0.0074\n",
      "Epoch 51/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7234 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.1041 - categorical_accuracy: 0.9666 - val_loss: 3.7234 - val_categorical_accuracy: 0.0074\n",
      "Epoch 52/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7215 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1077 - categorical_accuracy: 0.9660 - val_loss: 3.7215 - val_categorical_accuracy: 0.0074\n",
      "Epoch 53/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7256 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1041 - categorical_accuracy: 0.9679 - val_loss: 3.7256 - val_categorical_accuracy: 0.0074\n",
      "Epoch 54/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7243 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1046 - categorical_accuracy: 0.9685 - val_loss: 3.7243 - val_categorical_accuracy: 0.0074\n",
      "Epoch 55/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7308 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1058 - categorical_accuracy: 0.9665 - val_loss: 3.7308 - val_categorical_accuracy: 0.0074\n",
      "Epoch 56/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7325 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 468s 180ms/step - loss: 0.1047 - categorical_accuracy: 0.9667 - val_loss: 3.7325 - val_categorical_accuracy: 0.0074\n",
      "Epoch 57/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7318 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 468s 180ms/step - loss: 0.0927 - categorical_accuracy: 0.9706 - val_loss: 3.7318 - val_categorical_accuracy: 0.0074\n",
      "Epoch 58/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7331 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.1008 - categorical_accuracy: 0.9682 - val_loss: 3.7331 - val_categorical_accuracy: 0.0074\n",
      "Epoch 59/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7329 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0949 - categorical_accuracy: 0.9705 - val_loss: 3.7329 - val_categorical_accuracy: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7314 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0919 - categorical_accuracy: 0.9697 - val_loss: 3.7314 - val_categorical_accuracy: 0.0074\n",
      "Epoch 61/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7314 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0937 - categorical_accuracy: 0.9698 - val_loss: 3.7314 - val_categorical_accuracy: 0.0074\n",
      "Epoch 62/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7355 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0853 - categorical_accuracy: 0.9737 - val_loss: 3.7355 - val_categorical_accuracy: 0.0074\n",
      "Epoch 63/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7385 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0884 - categorical_accuracy: 0.9733 - val_loss: 3.7385 - val_categorical_accuracy: 0.0074\n",
      "Epoch 64/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7380 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0947 - categorical_accuracy: 0.9716 - val_loss: 3.7380 - val_categorical_accuracy: 0.0074\n",
      "Epoch 65/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7410 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0916 - categorical_accuracy: 0.9709 - val_loss: 3.7410 - val_categorical_accuracy: 0.0074\n",
      "Epoch 66/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7434 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0820 - categorical_accuracy: 0.9749 - val_loss: 3.7434 - val_categorical_accuracy: 0.0074\n",
      "Epoch 67/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7430 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0886 - categorical_accuracy: 0.9722 - val_loss: 3.7430 - val_categorical_accuracy: 0.0074\n",
      "Epoch 68/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7491 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0882 - categorical_accuracy: 0.9737 - val_loss: 3.7491 - val_categorical_accuracy: 0.0074\n",
      "Epoch 69/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7510 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0799 - categorical_accuracy: 0.9749 - val_loss: 3.7510 - val_categorical_accuracy: 0.0074\n",
      "Epoch 70/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7536 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0753 - categorical_accuracy: 0.9770 - val_loss: 3.7536 - val_categorical_accuracy: 0.0074\n",
      "Epoch 71/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7527 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0899 - categorical_accuracy: 0.9727 - val_loss: 3.7527 - val_categorical_accuracy: 0.0074\n",
      "Epoch 72/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7536 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0788 - categorical_accuracy: 0.9760 - val_loss: 3.7536 - val_categorical_accuracy: 0.0074\n",
      "Epoch 73/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7543 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0797 - categorical_accuracy: 0.9745 - val_loss: 3.7543 - val_categorical_accuracy: 0.0074\n",
      "Epoch 74/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7560 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0798 - categorical_accuracy: 0.9765 - val_loss: 3.7560 - val_categorical_accuracy: 0.0074\n",
      "Epoch 75/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7566 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0867 - categorical_accuracy: 0.9732 - val_loss: 3.7566 - val_categorical_accuracy: 0.0074\n",
      "Epoch 76/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7587 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0770 - categorical_accuracy: 0.9756 - val_loss: 3.7587 - val_categorical_accuracy: 0.0074\n",
      "Epoch 77/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7607 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0862 - categorical_accuracy: 0.9746 - val_loss: 3.7607 - val_categorical_accuracy: 0.0074\n",
      "Epoch 78/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7607 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0709 - categorical_accuracy: 0.9772 - val_loss: 3.7607 - val_categorical_accuracy: 0.0074\n",
      "Epoch 79/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7610 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0818 - categorical_accuracy: 0.9747 - val_loss: 3.7610 - val_categorical_accuracy: 0.0074\n",
      "Epoch 80/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7600 - categorical_accuracy: 0.0083\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0787 - categorical_accuracy: 0.9762 - val_loss: 3.7600 - val_categorical_accuracy: 0.0083\n",
      "Epoch 81/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7667 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0777 - categorical_accuracy: 0.9761 - val_loss: 3.7667 - val_categorical_accuracy: 0.0074\n",
      "Epoch 82/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7711 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0773 - categorical_accuracy: 0.9747 - val_loss: 3.7711 - val_categorical_accuracy: 0.0074\n",
      "Epoch 83/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7713 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0765 - categorical_accuracy: 0.9780 - val_loss: 3.7713 - val_categorical_accuracy: 0.0074\n",
      "Epoch 84/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7763 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0766 - categorical_accuracy: 0.9777 - val_loss: 3.7763 - val_categorical_accuracy: 0.0074\n",
      "Epoch 85/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7752 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0800 - categorical_accuracy: 0.9764 - val_loss: 3.7752 - val_categorical_accuracy: 0.0074\n",
      "Epoch 86/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7786 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0902 - categorical_accuracy: 0.9725 - val_loss: 3.7786 - val_categorical_accuracy: 0.0074\n",
      "Epoch 87/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7839 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0783 - categorical_accuracy: 0.9756 - val_loss: 3.7839 - val_categorical_accuracy: 0.0074\n",
      "Epoch 88/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7845 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0721 - categorical_accuracy: 0.9767 - val_loss: 3.7845 - val_categorical_accuracy: 0.0074\n",
      "Epoch 89/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7866 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0695 - categorical_accuracy: 0.9782 - val_loss: 3.7866 - val_categorical_accuracy: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7842 - categorical_accuracy: 0.0093\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0752 - categorical_accuracy: 0.9768 - val_loss: 3.7842 - val_categorical_accuracy: 0.0093\n",
      "Epoch 91/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7915 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0710 - categorical_accuracy: 0.9773 - val_loss: 3.7915 - val_categorical_accuracy: 0.0074\n",
      "Epoch 92/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7892 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0704 - categorical_accuracy: 0.9803 - val_loss: 3.7892 - val_categorical_accuracy: 0.0074\n",
      "Epoch 93/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7860 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0706 - categorical_accuracy: 0.9789 - val_loss: 3.7860 - val_categorical_accuracy: 0.0074\n",
      "Epoch 94/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7920 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0682 - categorical_accuracy: 0.9791 - val_loss: 3.7920 - val_categorical_accuracy: 0.0074\n",
      "Epoch 95/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7973 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0894 - categorical_accuracy: 0.9733 - val_loss: 3.7973 - val_categorical_accuracy: 0.0074\n",
      "Epoch 96/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7941 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0743 - categorical_accuracy: 0.9772 - val_loss: 3.7941 - val_categorical_accuracy: 0.0074\n",
      "Epoch 97/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7922 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0716 - categorical_accuracy: 0.9792 - val_loss: 3.7922 - val_categorical_accuracy: 0.0074\n",
      "Epoch 98/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.7908 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0682 - categorical_accuracy: 0.9791 - val_loss: 3.7908 - val_categorical_accuracy: 0.0074\n",
      "Epoch 99/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7964 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0822 - categorical_accuracy: 0.9768 - val_loss: 3.7964 - val_categorical_accuracy: 0.0074\n",
      "Epoch 100/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7978 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0716 - categorical_accuracy: 0.9785 - val_loss: 3.7978 - val_categorical_accuracy: 0.0074\n",
      "Epoch 101/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8038 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0783 - categorical_accuracy: 0.9773 - val_loss: 3.8038 - val_categorical_accuracy: 0.0074\n",
      "Epoch 102/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.7996 - categorical_accuracy: 0.0074 1s - l\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0887 - categorical_accuracy: 0.9737 - val_loss: 3.7996 - val_categorical_accuracy: 0.0074\n",
      "Epoch 103/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8029 - categorical_accuracy: 0.0074 0s - loss: 3.7994 - categorical_accura\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0787 - categorical_accuracy: 0.9762 - val_loss: 3.8029 - val_categorical_accuracy: 0.0074\n",
      "Epoch 104/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8115 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0795 - categorical_accuracy: 0.9764 - val_loss: 3.8115 - val_categorical_accuracy: 0.0074\n",
      "Epoch 105/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8150 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0727 - categorical_accuracy: 0.9788 - val_loss: 3.8150 - val_categorical_accuracy: 0.0074\n",
      "Epoch 106/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8127 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0720 - categorical_accuracy: 0.9784 - val_loss: 3.8127 - val_categorical_accuracy: 0.0074\n",
      "Epoch 107/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8169 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0687 - categorical_accuracy: 0.9788 - val_loss: 3.8169 - val_categorical_accuracy: 0.0074\n",
      "Epoch 108/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8160 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0679 - categorical_accuracy: 0.9795 - val_loss: 3.8160 - val_categorical_accuracy: 0.0074\n",
      "Epoch 109/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8166 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0713 - categorical_accuracy: 0.9801 - val_loss: 3.8166 - val_categorical_accuracy: 0.0074\n",
      "Epoch 110/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8198 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0692 - categorical_accuracy: 0.9808 - val_loss: 3.8198 - val_categorical_accuracy: 0.0074\n",
      "Epoch 111/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8126 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0784 - categorical_accuracy: 0.9771 - val_loss: 3.8126 - val_categorical_accuracy: 0.0074\n",
      "Epoch 112/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8182 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0683 - categorical_accuracy: 0.9790 - val_loss: 3.8182 - val_categorical_accuracy: 0.0074\n",
      "Epoch 113/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8175 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 469s 180ms/step - loss: 0.0706 - categorical_accuracy: 0.9791 - val_loss: 3.8175 - val_categorical_accuracy: 0.0074\n",
      "Epoch 114/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8226 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 468s 180ms/step - loss: 0.0636 - categorical_accuracy: 0.9809 - val_loss: 3.8226 - val_categorical_accuracy: 0.0074\n",
      "Epoch 115/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8243 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 470s 180ms/step - loss: 0.0615 - categorical_accuracy: 0.9821 - val_loss: 3.8243 - val_categorical_accuracy: 0.0074\n",
      "Epoch 116/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8257 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0604 - categorical_accuracy: 0.9825 - val_loss: 3.8257 - val_categorical_accuracy: 0.0074\n",
      "Epoch 117/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8267 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0638 - categorical_accuracy: 0.9817 - val_loss: 3.8267 - val_categorical_accuracy: 0.0074\n",
      "Epoch 118/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8329 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0584 - categorical_accuracy: 0.9827 - val_loss: 3.8329 - val_categorical_accuracy: 0.0074\n",
      "Epoch 119/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8315 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0583 - categorical_accuracy: 0.9839 - val_loss: 3.8315 - val_categorical_accuracy: 0.0074\n",
      "Epoch 120/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8321 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0575 - categorical_accuracy: 0.9829 - val_loss: 3.8321 - val_categorical_accuracy: 0.0074\n",
      "Epoch 121/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8252 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0674 - categorical_accuracy: 0.9811 - val_loss: 3.8252 - val_categorical_accuracy: 0.0074\n",
      "Epoch 122/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8339 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0625 - categorical_accuracy: 0.9820 - val_loss: 3.8339 - val_categorical_accuracy: 0.0074\n",
      "Epoch 123/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8387 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0656 - categorical_accuracy: 0.9816 - val_loss: 3.8387 - val_categorical_accuracy: 0.0074\n",
      "Epoch 124/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8414 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0534 - categorical_accuracy: 0.9835 - val_loss: 3.8414 - val_categorical_accuracy: 0.0074\n",
      "Epoch 125/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8370 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0622 - categorical_accuracy: 0.9816 - val_loss: 3.8370 - val_categorical_accuracy: 0.0074\n",
      "Epoch 126/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8387 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0666 - categorical_accuracy: 0.9813 - val_loss: 3.8387 - val_categorical_accuracy: 0.0074\n",
      "Epoch 127/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8463 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0553 - categorical_accuracy: 0.9832 - val_loss: 3.8463 - val_categorical_accuracy: 0.0074\n",
      "Epoch 128/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8452 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0562 - categorical_accuracy: 0.9838 - val_loss: 3.8452 - val_categorical_accuracy: 0.0074\n",
      "Epoch 129/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8436 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0674 - categorical_accuracy: 0.9807 - val_loss: 3.8436 - val_categorical_accuracy: 0.0074\n",
      "Epoch 130/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8479 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0557 - categorical_accuracy: 0.9843 - val_loss: 3.8479 - val_categorical_accuracy: 0.0074\n",
      "Epoch 131/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8548 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 470s 181ms/step - loss: 0.0578 - categorical_accuracy: 0.9835 - val_loss: 3.8548 - val_categorical_accuracy: 0.0074\n",
      "Epoch 132/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8544 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 468s 179ms/step - loss: 0.0522 - categorical_accuracy: 0.9841 - val_loss: 3.8544 - val_categorical_accuracy: 0.0074\n",
      "Epoch 133/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8590 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 468s 180ms/step - loss: 0.0569 - categorical_accuracy: 0.9838 - val_loss: 3.8590 - val_categorical_accuracy: 0.0074\n",
      "Epoch 134/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8654 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 468s 180ms/step - loss: 0.0566 - categorical_accuracy: 0.9850 - val_loss: 3.8654 - val_categorical_accuracy: 0.0074\n",
      "Epoch 135/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8669 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 469s 180ms/step - loss: 0.0571 - categorical_accuracy: 0.9832 - val_loss: 3.8669 - val_categorical_accuracy: 0.0074\n",
      "Epoch 136/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8661 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0608 - categorical_accuracy: 0.9836 - val_loss: 3.8661 - val_categorical_accuracy: 0.0074\n",
      "Epoch 137/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8683 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0518 - categorical_accuracy: 0.9850 - val_loss: 3.8683 - val_categorical_accuracy: 0.0074\n",
      "Epoch 138/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8693 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0638 - categorical_accuracy: 0.9826 - val_loss: 3.8693 - val_categorical_accuracy: 0.0074\n",
      "Epoch 139/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8654 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 467s 179ms/step - loss: 0.0541 - categorical_accuracy: 0.9844 - val_loss: 3.8654 - val_categorical_accuracy: 0.0074\n",
      "Epoch 140/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8654 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0564 - categorical_accuracy: 0.9847 - val_loss: 3.8654 - val_categorical_accuracy: 0.0074\n",
      "Epoch 141/150\n",
      "135/135 [==============================] - ETA: 0s - loss: 3.8654 - categorical_accuracy: 0.00 - 6s 46ms/step - loss: 3.8660 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0545 - categorical_accuracy: 0.9833 - val_loss: 3.8660 - val_categorical_accuracy: 0.0074\n",
      "Epoch 142/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8636 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 467s 179ms/step - loss: 0.0524 - categorical_accuracy: 0.9851 - val_loss: 3.8636 - val_categorical_accuracy: 0.0074\n",
      "Epoch 143/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8718 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 469s 180ms/step - loss: 0.0503 - categorical_accuracy: 0.9854 - val_loss: 3.8718 - val_categorical_accuracy: 0.0074\n",
      "Epoch 144/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8748 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 467s 179ms/step - loss: 0.0569 - categorical_accuracy: 0.9839 - val_loss: 3.8748 - val_categorical_accuracy: 0.0074\n",
      "Epoch 145/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8638 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 467s 179ms/step - loss: 0.0600 - categorical_accuracy: 0.9838 - val_loss: 3.8638 - val_categorical_accuracy: 0.0074\n",
      "Epoch 146/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8685 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 179ms/step - loss: 0.0574 - categorical_accuracy: 0.9831 - val_loss: 3.8685 - val_categorical_accuracy: 0.0074\n",
      "Epoch 147/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8750 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 465s 178ms/step - loss: 0.0550 - categorical_accuracy: 0.9842 - val_loss: 3.8750 - val_categorical_accuracy: 0.0074\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8782 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 464s 178ms/step - loss: 0.0541 - categorical_accuracy: 0.9845 - val_loss: 3.8782 - val_categorical_accuracy: 0.0074\n",
      "Epoch 149/150\n",
      "135/135 [==============================] - 6s 45ms/step - loss: 3.8777 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 466s 179ms/step - loss: 0.0471 - categorical_accuracy: 0.9869 - val_loss: 3.8777 - val_categorical_accuracy: 0.0074\n",
      "Epoch 150/150\n",
      "135/135 [==============================] - 6s 46ms/step - loss: 3.8776 - categorical_accuracy: 0.0074\n",
      "2605/2605 [==============================] - 467s 179ms/step - loss: 0.0536 - categorical_accuracy: 0.9849 - val_loss: 3.8776 - val_categorical_accuracy: 0.0074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2897e0d7a58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        generator=train_generator,\n",
    "        steps_per_epoch=512//batch_size,\n",
    "        epochs=150,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=128//batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"resnet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys,os\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHwCAYAAAAIDnN0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xmc3FWd7//3p7au6n1Np7uzdCAhJIGQQMAoqCDoZRNcUHHEEUcnv6vORR3vzKgzP0dnudd5DON4vY46ODKjI+IwIC4MOoiCwCBIgiGELCSQrbP1vm+1nPvHqV7S6e50kq7+djqv5+NRj/pWfb/17dNFCG/O+ZxzzDknAAAABCcUdAMAAADOdgQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyADMaWa218yuCbodADAZAhkAAEDACGQAAAABI5ABOCuYWZ6ZfdnMDmUfXzazvOy5SjN7yMzazazVzJ40s1D23J+Y2UEz6zKznWZ2dbC/CYC5KBJ0AwBghvyppPWS1khykn4k6c8k/f+SPiWpQVJV9tr1kpyZLZf0B5Iudc4dMrN6SeGZbTaAswE9ZADOFu+T9BfOuUbnXJOkL0h6f/ZcUlKNpMXOuaRz7knnN/pNS8qTtNLMos65vc65VwJpPYA5jUAG4GxRK2nfqNf7su9J0t9K2i3pETN71cw+LUnOud2SPiHp85Iazez7ZlYrAJhmBDIAZ4tDkhaPer0o+56cc13OuU85586R9FZJfzhUK+ac+55z7orsZ52kv5nZZgM4GxDIAJwt7pX0Z2ZWZWaVkj4n6buSZGY3mtlSMzNJnfJDlWkzW25mb8oW//dL6sueA4BpRSADcLb4K0kbJW2R9KKk57PvSdIySY9K6pb0a0lfc849Ll8/9kVJzZKOSJon6bMz2moAZwXzdasAAAAICj1kAAAAASOQAQAABIxABgAAEDACGQAAQMAIZAAAAAE74/ayrKysdPX19UE3AwAA4IQ2bdrU7JyrOtF1Z1wgq6+v18aNG4NuBgAAwAmZ2b4TX8WQJQAAQOByHsjMLGxmvzWzh8Y5l2dm/2Zmu83sWTOrz3V7AAAAZpuZ6CH7uKTtE5z7kKQ259xSSX8vNu0FAABnoZzWkJnZAkk3SPprSX84ziU3S/p89vh+SV81M3MnuZ9TMplUQ0OD+vv7T6e5GCUej2vBggWKRqNBNwUAgDkv10X9X5b0x5KKJjhfJ+mAJDnnUmbWIalCfiPfKWtoaFBRUZHq6+tlZqfTXkhyzqmlpUUNDQ1asmRJ0M0BAGDOy9mQpZndKKnRObdpssvGee+43jEz22BmG81sY1NT03Ef6O/vV0VFBWFsmpiZKioq6HEEAGCG5LKG7HJJN5nZXknfl/QmM/vumGsaJC2UJDOLSCqR1Dr2Rs65u5xz65xz66qqxl/KgzA2vfg+AQCYOTkLZM65zzjnFjjn6iXdKumXzrnbxlz2Y0kfyB7fkr3mpOrHZoP29nZ97WtfO+nPXX/99Wpvb89BiwAAwJlkxtchM7O/MLObsi+/JanCzHbLF/1/eqbbMx0mCmTpdHrSzz388MMqLS3NVbMAAMAZYkZW6nfOPS7p8ezx50a93y/pXTPRhlz69Kc/rVdeeUVr1qxRNBpVYWGhampqtHnzZm3btk1ve9vbdODAAfX39+vjH/+4NmzYIGlk14Hu7m5dd911uuKKK/T000+rrq5OP/rRj5RIJAL+zQAAwEw447ZOOpEv/OQlbTvUOa33XFlbrD9/66oJz3/xi1/U1q1btXnzZj3++OO64YYbtHXr1uEZinfffbfKy8vV19enSy+9VO985ztVUVFxzD127dqle++9V9/85jf17ne/Ww888IBuu23sCC8AAJiL5lwgmw0uu+yyY5aL+MpXvqIHH3xQknTgwAHt2rXruEC2ZMkSrVmzRpJ0ySWXaO/evTPWXgAAEKw5F8gm68maKQUFBcPHjz/+uB599FH9+te/Vn5+vq688spxl5PIy8sbPg6Hw+rr65uRtgIAgOCxufg0KCoqUldX17jnOjo6VFZWpvz8fO3YsUPPPPPMDLcOAADMdnOuhywIFRUVuvzyy3XBBRcokUiourp6+Ny1116rb3zjG1q9erWWL1+u9evXB9hSAAAwG9mZtuzXunXr3MaNG495b/v27VqxYkVALZq7+F4BADg9ZrbJObfuRNfRQwYAAOam1KCU7JUsNPEjNDuqtwhkAADg9DgnJfukVP/IczRfKqw+tcDT1ybt+7XUskvqbpR6mvw9z32TdP5bpYJRKxVkMlLbHunwC9LhzdKRrVLnIan7qNR33G6Mx1r3IenGL518+3KAQAYAAEYM9kqN26UjL0iHt0jNu6TBLv/+YI9kJoVjUiRPchmpr90HqEzy+HuFY1JxnVRU41+7jOTSUiY9chyKSIlyKb/ch7hDv5WOvCgpW1IVSUiFVT70bfuR9NAfSkte769tfVVq3SOlB/y1oag073yp4lxp8et8IMwr9J91mTEPJ9VcNCNf6VQQyAAAOBs4J3UckA4+70NP58GRYbuhc62vSl2HRz6TV+IDTuF8KVYgxfJ9TkoPSOlBSSYlSqV4qRQv8ddE8qRIXBro8vfsaJC6jvogZ9HsMGFYsrA/ziR9oGt9xX9m3krpys9I9VdI8y+U8or8Z53zQW3bD6Ud/+F/dsVSadmbpYplPlzNWylFYgF9waeHQAYAwGzgnK936mmWelv8EF3JQqm41geY0bqOSPufkQ4863uxzHwYiub7Ryz7LEnt+6W2vX5Yr6/NvxeKSiV1/jiT8c8ldX5IsHyJVLlcqlktlS72954NzHybalZLV3/uxNefYQhkAACcqkzG9yodfdHXTkXzR3qJ0kkpk/LDc+XnSJXLRoJVsl868Iyvk2p+2fcOte6RBsbZ+m84PJk02O2HDZO9/lwk4XuRLOTrppK9fmgxmX24jA91ZfXSypul6gukuov9cyTv+J+FwBDIAlBYWKju7m4dOnRId9xxh+6///7jrrnyyit15513at26iWfKfvnLX9aGDRuUn+//L+j666/X9773PZWWluas7QBwxkinpPBJ/Geur01q3u2H2YaDTc+xAWf0cV+7r7VK9kzt/rFCqXatD08HnvU9YBbyganiXGnBZT545VdKBZW+/qrjgO/daj/gr40V+JqowvnSovXS/NWTD9E5N3t6uDApAlmAamtrxw1jU/XlL39Zt91223Age/jhh6eraQAwswa6pcZtvq6p87CfIRfN94XeiTIpNSC175Pa9kndR3z9USTPhxYp2xOV8kGp66j/fH+7VLpIWnCpf8QKpaYdPkS17fGfC0V9UXn3Uam3eeL2HTMUWCBFE7626eL3+x6q6gt8DdVQaEsP+PuGopJJanpZOrjJPzJJP7vvnDf6wvO8otx9r4SxMwaBbBr8yZ/8iRYvXqyPfvSjkqTPf/7zMjM98cQTamtrUzKZ1F/91V/p5ptvPuZze/fu1Y033qitW7eqr69PH/zgB7Vt2zatWLHimL0sP/KRj+i5555TX1+fbrnlFn3hC1/QV77yFR06dEhXXXWVKisr9dhjj6m+vl4bN25UZWWlvvSlL+nuu++WJH34wx/WJz7xCe3du1fXXXedrrjiCj399NOqq6vTj370IyUSiZn7sgCcHZzztUtHt/owVbpYKlss5Vf4nqiuI36IreE30p4npIbnfKAaEooc+1qSZH7GXnGNH4pLDR47uy4U9kGp6jxpyRt8kGt+Wdr/rLT1AX9dJC5VLZdq1mQLyrNBbsElvjC8cplva6xgVE1W4vSDTd0l0pr3nt49MKfNvUD2009np8tOo/kXStd9ccLTt956qz7xiU8MB7L77rtPP/vZz/TJT35SxcXFam5u1vr163XTTTfJJviX+utf/7ry8/O1ZcsWbdmyRRdffPHwub/+679WeXm50um0rr76am3ZskV33HGHvvSlL+mxxx5TZWXlMffatGmT/vmf/1nPPvusnHN6zWteoze+8Y0qKyvTrl27dO+99+qb3/ym3v3ud+uBBx7QbbfdNg1fEoBZZaDbD4klyo4vCB9tsFdq3ul7jRq3SS2vZofEqqWi+X45grxC37sUKxx1XOADVdMO/7mOBl/bNNjjZ8o1vzx+PZSFfJga/bpmjfTaP/BDcCULfOhKlPmg1Nfu15IKRfzQ3qnOoOs85Gu8yuon/z6AgMy9QBaAtWvXqrGxUYcOHVJTU5PKyspUU1OjT37yk3riiScUCoV08OBBHT16VPPnzx/3Hk888YTuuOMOSdLq1au1evXq4XP33Xef7rrrLqVSKR0+fFjbtm075vxYTz31lN7+9reroKBAkvSOd7xDTz75pG666SYtWbJEa9askSRdcskl2rt37zR9CwCmXX+nXwOqY/9IgXg66QNPf7sPK5mUDy/55b735+hW6cBzPiTJ+cCTKJcKqnxdUkGlf911xF/TtlfD6z2F8/wMu8FeP4Q31Pt0Ihb2tU+xQt+jlFcorX63H8arvsD3MLXv94+eRl8jVTTfP+at8O0fTzjq158qrDr977K49vTvAeTQ3Atkk/Rk5dItt9yi+++/X0eOHNGtt96qe+65R01NTdq0aZOi0ajq6+vV398/6T3G6z3bs2eP7rzzTj333HMqKyvT7bfffsL7TLY/aV7eyKyacDh8zNAogBzIjFoEM5PyRdrNu6SW3b7nJxL3j3DUr0bedcTXULW+KnUdmuTG5muWQhEfzoaG9/JK/PDbirf6oNPb7JdR6GnySykcedE/F8zz6zZd9F4fiuatkMqWjBTBO5cNfW2+t22wO/vclX3ukQrn+c9VLD3xjL35F0zL1wnMVXMvkAXk1ltv1e///u+rublZv/rVr3Tfffdp3rx5ikajeuyxx7Rv375JP/+GN7xB99xzj6666ipt3bpVW7ZskSR1dnaqoKBAJSUlOnr0qH7605/qyiuvlCQVFRWpq6vruCHLN7zhDbr99tv16U9/Ws45Pfjgg/rXf/3XnPzeALK6G/1im4d+6wNX215fhN7TNPFnIgk/rDi6h6q4xq9qvuQNvhaq8jwflCJxH5ZC0eywYdHIljTO+V6zwW4/+2469uYz84Fuot4rANOKQHYivS3ZLv/J/1JatWqVurq6VFdXp5qaGr3vfe/TW9/6Vq1bt05r1qzR+eefP+nnP/KRj+iDH/ygVq9erTVr1uiyyy6TJF100UVau3atVq1apXPOOUeXX3758Gc2bNig6667TjU1NXrssceG37/44ot1++23D9/jwx/+sNauXcvwJOaGdErq7/C9NwNdvodoaLady/gC8lS/X0U81Z99PTBynB79elBK9fmhwf4OX/PU35F9dGa3idHIauayUZsSjzpODfihOMlfU7rI1yotvz67qGdk5NriWt+jVLFUihf7MJUe9I9Y4akVj5v5e8WLp+97BjCjbLLhrdlo3bp1buPGjce8t337dq1YsWL6f9jQNg2hsN+O4SybPpyz7xUYMtSz09via6NCYf8Y6JaOviQd2eKLzXsapb6hEDZOofjpCEWzYabEP/KGjov98ga+ocfufzd0LDeyztO8lX6NqfmrfQ8WAEgys03OuYkXFc2ih2wyyV6/8Wk6nd25nuUhMMeks3VHofDI/3Bk0tmVwLP1hWaSzM9uixaMv9BmatCvH9W+3z93N47ULLnMSA9RamCkpqm3xT9PVjgezvP76BXXSfNW+T3zEmV+37xEqV+/KZMaWf5gaG2q4cdQfVYsezzmXDhveob3AOA0Ecgm09957DGBDLPJ0J/PWKEPFUNF2O37fVH40JpM0YQPSIdf8I+mHdnhuOyyCJIk80XlshPPrIvEs+syjapf6m8/dikDyddHFVSOLHOQSfmfUVDla6TmX+jXpBqa/ReOZYvf0/64epVfF+pkVloHgDMUf9NNZqDTT+F2ThrokIqqg24RZqvRQ295xdm1n0b1vGTSvsdpqO5I8sGpcbvUtNPPvEv1+2tS/X6fu1Sffw6FR4bTwlH/udY9foaeJMl8T5FzfgbchMwXiNdc5Ns3tK6UhUZqmOR8L1gsuximbCRopQZ8r/FAV7b3bFS5Q36lVLrQ104V1/k1rBi2A4ApmzOBzDk34aKrpySd9P/xKZrv/0PXffTk90U7g51ptYWnZGgq/3DBtWXXd8oWdWdSI9uqyPkhuKGhuO5GX9fU3eT/bHQfHdnsVxpZ+ykUzgaY3gmbIZkPMEO9WUM9UPFSqSjh29Hf4UNYqt8Hn5U3jyxw2d/pf4acXzhzKBTJjWxCnCjz60ERkgBgVpoT6SIej6ulpUUVFRXTF8oGsj0NedlZS91HfY9Zfvn03H8Wc86ppaVF8Xh8Jn+o/357W6TeNt/709si9baOHPe1+6GseLHvEQpFR2382zeyBYpLj1r7KT2ymGY66XuB+lp9oJo0JJ1Aosyv41Q4zxdyF9X4HtT8ymxPWbZOymV8W/OKRoa8hwrCi2r9Gk6V5/keKQDAWWtOBLIFCxaooaFBTU2TrPdzsnpb/HBRe3b9sM4W6XCPr3k5C8TjcS1YsGDqHxjo8gta9rZke2w6fV3R8HHHyBYofW2+52Zo5fHUwLELW441tOxIvNRvyjt0T5fxdUpD+80NzdALRXxxdyiUfY74ob5w1F9bce5ImMor9GFwaOHOvKKRGXahqP956ZRf+iC/0n8mv/LUt28BAGAccyKQRaNRLVmyZPpumMlIdy6Tzr1KWv9P/r0HvyK9/DPpj145M/dBSw36Xpv+zlHrMI1ajyk94HuaBketyL2tJ/u6x4eVodl2mdTI+/2dPohNVrs0tKzA0CKThdW+dmkoJIVj2XPlvgcyv2LkeCiIjZ0J57LLDTBDDgAwB8yJQDbtjrzgw8vSa0beW/YW6YV7pYbn/Aa4MymT8VuotO31G/i2H/Dty6/wPTYF8/xQXE/TyBYpY4/720/uZ4ZjvjcpVuSH0yw7i0/yPU6xAh+UShZI574pu7p4rVRQ4bduGeplipf4mqjpXsPN7KxbFw4AMHcRyMaz61H/fO7VI++d+yYfRF7+2fGBbGgCwPDMuD7f8xQr9GslxUt9oEn2+J6n3ma/4OzhLf45k8yGnwIfXpyTlF29u22f3/NubL1TrGjiXqnhjYSr/P5xQ8cFlSMBKZx37JpM4TwfvIZm3jEkBwDAjCGQjWf3o1LNGqmwauS9RKm06LXS9of8DLa9T0n7n/G9Ty59aj8nmu/XWorm+6G/zsN++HB4S5awn1FXf4VUuczvZzc0gy4az27Xkp3lF4750JVfkV1PCgAAnCkIZGP1tUkNv5Fe/6njz513rfTIn0oP/0+peIHf/Ld0oS8sjyZ8SIrmj6wIPtDthwr72n1oixX6XrBEqV+CoGLp6dWjRfL8kGHJSRTfAwCAWYdANlb7fr+W0+j6sSGXfkgqW+xXGC9dTA0TAACYFgSysWoukj7+wvjnoglpxVtntj0AAGDOI5CNh54vAAAwg1jECQAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIWM4CmZnFzew3ZvaCmb1kZl8Y55rbzazJzDZnHx/OVXsAAABmq1yu1D8g6U3OuW4zi0p6ysx+6px7Zsx1/+ac+4MctgMAAGBWy1kgc845Sd3Zl9Hsw+Xq5wEAAJypclpDZmZhM9ssqVHSz51zz45z2TvNbIuZ3W9mC3PZHgAAgNkop4HMOZd2zq2RtEDSZWZ2wZhLfiKp3jm3WtKjkr493n3MbIOZbTSzjU1NTblsMgAAwIybkVmWzrl2SY9LunbM+y3OuYHsy29KumSCz9/lnFvnnFtXVVWV07YCAADMtFzOsqwys9LscULSNZJ2jLmmZtTLmyRtz1V7AAAAZqtczrKskfRtMwvLB7/7nHMPmdlfSNronPuxpDvM7CZJKUmtkm7PYXsAAABmJfOTIc8c69atcxs3bgy6GQAAACdkZpucc+tOdB0r9QMAAASMQAYAABAwAhkAAEDACGQAAAABI5ABAAAEjEAGAAAQMAIZAABAwAhkAAAAASOQAQAABIxABgAAEDACGQAAQMAIZAAAAAEjkAEAAASMQAYAABAwAhkAAEDACGQAAAABI5ABAAAEjEAGAAAQMAIZAABAwAhkAAAAASOQAQAABIxABgAAEDACGQAAQMAIZAAAAAEjkAEAAASMQAYAABAwAhkAAEDACGQAAAABI5ABAAAEjEAGAAAQMAIZAABAwAhkAAAAASOQAQAABIxABgAAEDACGQAAQMAIZAAAAAEjkAEAAASMQAYAABAwAhkAAEDACGQAAAABI5ABAAAEjEAGAAAQMAIZAABAwHIWyMwsbma/MbMXzOwlM/vCONfkmdm/mdluM3vWzOpz1R4AAIDZKpc9ZAOS3uScu0jSGknXmtn6Mdd8SFKbc26ppL+X9Dc5bA8AAMCslLNA5rzu7Mto9uHGXHazpG9nj++XdLWZWa7aBAAAMBvltIbMzMJmtllSo6SfO+eeHXNJnaQDkuScS0nqkFQxzn02mNlGM9vY1NSUyyYDAADMuJwGMudc2jm3RtICSZeZ2QVjLhmvN2xsL5qcc3c559Y559ZVVVXloqkAAACBmZFZls65dkmPS7p2zKkGSQslycwikkoktc5EmwAAAGaLXM6yrDKz0uxxQtI1knaMuezHkj6QPb5F0i+dc8f1kAEAAMxlkRzeu0bSt80sLB/87nPOPWRmfyFpo3Pux5K+JelfzWy3fM/YrTlsDwAAwKyUs0DmnNsiae04739u1HG/pHflqg0AAABnAlbqBwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgOQtkZrbQzB4zs+1m9pKZfXyca640sw4z25x9fC5X7QEAAJitIjm8d0rSp5xzz5tZkaRNZvZz59y2Mdc96Zy7MYftAAAAmNVy1kPmnDvsnHs+e9wlabukulz9PAAAgDPVjNSQmVm9pLWSnh3n9GvN7AUz+6mZrZqJ9gAAAMwmuRyylCSZWaGkByR9wjnXOeb085IWO+e6zex6ST+UtGyce2yQtEGSFi1alOMWAwAAzKyc9pCZWVQ+jN3jnPvB2PPOuU7nXHf2+GFJUTOrHOe6u5xz65xz66qqqnLZZAAAgBmXy1mWJulbkrY75740wTXzs9fJzC7LtqclV20CAACYjXI5ZHm5pPdLetHMNmff+6ykRZLknPuGpFskfcTMUpL6JN3qnHM5bBMAAMCsk7NA5px7SpKd4JqvSvpqrtoAAABwJmClfgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAI2JQCmZl93MyKzfuWmT1vZm85wWcWmtljZrbdzF4ys4+Pc42Z2VfMbLeZbTGzi0/1FwEAADhTTbWH7Pecc52S3iKpStIHJX3xBJ9JSfqUc26FpPWSPmZmK8dcc52kZdnHBklfn2rDAQAA5oqpBjLLPl8v6Z+dcy+Mem9czrnDzrnns8ddkrZLqhtz2c2SvuO8ZySVmlnNlFsPAAAwB0w1kG0ys0fkA9l/mlmRpMxUf4iZ1UtaK+nZMafqJB0Y9bpBx4c2AACAOS0yxes+JGmNpFedc71mVi4/bHlCZlYo6QFJn8gOex5zepyPuHHusUF+SFOLFi2aYpMBAADODFPtIXutpJ3OuXYzu03Sn0nqONGHzCwqH8bucc79YJxLGiQtHPV6gaRDYy9yzt3lnFvnnFtXVVU1xSYDAACcGaYayL4uqdfMLpL0x5L2SfrOZB8wM5P0LUnbnXNfmuCyH0v63exsy/WSOpxzh6fYJgAAgDlhqkOWKeecM7ObJf0f59y3zOwDJ/jM5ZLeL+lFM9ucfe+zkhZJknPuG5Ielq9L2y2pV1McBgUAAJhLphrIuszsM/IB6/VmFpYUnewDzrmndOKZmE7Sx6bYBgAAgDlpqkOW75E0IL8e2RH5mZB/m7NWAQAAnEWmFMiyIeweSSVmdqOkfufcpDVkAAAAmJqpbp30bkm/kfQuSe+W9KyZ3ZLLhgEAAJwtplpD9qeSLnXONUqSmVVJelTS/blqGAAAwNliqjVkoaEwltVyEp8FAADAJKbaQ/YzM/tPSfdmX79HfskKAAAAnKYpBTLn3B+Z2Tvl1xYzSXc55x7MacsAAADOElPtIZNz7gH5bZAAAAAwjSYNZGbWpXE2+5bvJXPOueKctAoAAOAsMmkgc84VzVRDAAAAzlbMlAQAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEMgAAgIARyAAAAAJGIAMAAAgYgQwAACBgBDIAAICAEcgAAAACRiADAAAIGIEMAAAgYAQyAACAgBHIAAAAAkYgAwAACBiBDAAAIGAEsjG6+pN64uUmNXcPBN0UAABwliCQjbG/tVe/e/dvtGlfW9BNAQAAZwn+jEe2AAAgAElEQVQC2RiJaFiS1J9MB9wSAABwtiCQjZGI+UDWN0ggAwAAM4NANsZQD1kfPWQAAGCGEMjGiBPIAADADCOQjZEX8V9JP0OWAABghhDIxjAzJaJhesgAAMCMIZCNIxEjkAEAgJlDIBtHIhpW32Am6GYAAICzRM4CmZndbWaNZrZ1gvNXmlmHmW3OPj6Xq7acrHg0xDpkAABgxkRyeO9/kfRVSd+Z5JonnXM35rANpyQRCxPIAADAjMlZD5lz7glJrbm6fy5R1A8AAGZS0DVkrzWzF8zsp2a2KuC2DIsTyAAAwAwKMpA9L2mxc+4iSf9X0g8nutDMNpjZRjPb2NTUlPOG+aJ+AhkAAJgZgQUy51ync647e/ywpKiZVU5w7V3OuXXOuXVVVVU5bxs1ZAAAYCYFFsjMbL6ZWfb4smxbWoJqz2jxCEOWAABg5uRslqWZ3SvpSkmVZtYg6c8lRSXJOfcNSbdI+oiZpST1SbrVOedy1Z6TkYgxZAkAAGZOzgKZc+69Jzj/VfllMWadeDSs/iQLwwIAgJkR9CzLWSkRDWswnVEqTSgDAAC5RyAbRyLmv5b+FIEMAADkHoFsHIloWJKoIwMAADOCQDaOeDaQsfQFAACYCQSycSRiBDIAADBzCGTjGB6yJJABAIAZQCAbBzVkAABgJhHIxhGP0UMGAABmDoFsHPEINWQAAGDmEMjGkaCHDAAAzCAC2ThGashYGBYAAOQegWwczLIEAAAziUA2jvjQ1kkEMgAAMAMIZOOIhUMKGYEMAADMDALZOMxMiWiYdcgAAMCMIJBNIBELU0MGAABmBIFsAvEogQwAAMwMAtkEEtEwNWQAAGBGEMgmkIhRQwYAAGYGgWwC8QhDlgAAYGYQyCYQj4XVl2SlfgAAkHsEsgkkoiH1M2QJAABmAIFsAglmWQIAgBlCIJtAIsYsSwAAMDMIZBNgHTIAADBTCGQTYB0yAAAwUwhkE0hEw0qmnZJpZloCAIDcIpBNIBELSxK9ZAAAIOcIZBOIR30go44MAADkGoFsAolsIOsfZMgSAADkFoFsAvSQAQCAmUIgm0Ai5r8aAhkAAMg1AtkEhnvI2D4JAADkGIFsAsM1ZCkCGQAAyC0C2QSGl72ghwwAAOQYgWwCCYr6AQDADCGQTYBABgAAZgqBbALxGEX9AABgZhDIJjBc1E8PGQAAyDEC2QSi4ZAiIWPIEgAA5ByBbBKJaFh9bJ0EAAByjEA2ibxomB4yAACQcwSySSRiIWrIAABAzuUskJnZ3WbWaGZbJzhvZvYVM9ttZlvM7OJcteVU+SFLAhkAAMitXPaQ/Yukayc5f52kZdnHBklfz2FbTkkiGmbrJAAAkHM5C2TOuScktU5yyc2SvuO8ZySVmllNrtpzKuL0kAEAgBkQZA1ZnaQDo143ZN+bNRKxMDVkAAAg54IMZDbOe27cC802mNlGM9vY1NSU42aNSDDLEgAAzIAgA1mDpIWjXi+QdGi8C51zdznn1jnn1lVVVc1I4yQCGQAAmBlBBrIfS/rd7GzL9ZI6nHOHA2zPceIxFoYFAAC5F8nVjc3sXklXSqo0swZJfy4pKknOuW9IeljS9ZJ2S+qV9MFcteVUJaLUkAEAgNzLWSBzzr33BOedpI/l6udPh6EhS+eczMYreQMAADh9rNQ/iXg0pHTGKZked64BAADAtCCQTSIeDUsShf0AACCnCGSTSMR8IBsgkAEAgBwikE0iQQ8ZAACYAQSySRDIAADATCCQTSKeHbJkP0sAAJBLBLJJ0EMGAABmAoFsEkOBjMVhAQBALhHIJpEYHrJk+yQAAJA7BLJJMGQJAABmAoFsEiwMCwAAZgKBbBLxqP96+pllCQAAcohANok4Rf0AAGAGEMgmEQ2HFA0bQ5YAACCnCGQnEI+GCWQAACCnCGQnkIiGGbIEAAA5RSA7gUQszNZJAAAgpwhkJ5BgyBIAAOQYgewECvIi6uxLBd0MAAAwhxHITmBhWUL7W3uDbgYAAJjDCGQnUF9ZoEMdfRT2AwCAnCGQncCSygI5J3rJAABAzhDITqC+okCStLe5J+CWAACAuYpAdgL1ldlA1kIgAwAAuUEgO4GSRFTlBTHtaWbIEgAA5AaBbArqK/IZsgQAADlDIJuC+soChiwBAEDOEMimoL6iQIc7+tlCCQAA5ASBbAqGCvv3tdJLBgAAph+BbAqWsPQFAADIIQLZFNRX5ksSMy0BAEBOEMimoCgeVWVhjB4yAACQEwSyKaqvYKYlAADIDQLZFLH0BQAAyBUC2RQtqSzQ0c4B9Q6mgm4KAACYYwhkU7S4whf276WwHwAATDMC2RTVV7DJOAAAyA0C2RQNLQ67h5mWAABgmhHIpqgwL6KqojyWvgAAANOOQHYSlrD0BQAAyAEC2Umor8xntX4AADDtCGQnob6yQM3dA+rqTwbdFAAAMIcQyE7CBbUlkqSNe9sCbgkAAJhLchrIzOxaM9tpZrvN7NPjnL/dzJrMbHP28eFctud0veacchXEwvr59qNBNwUAAMwhOQtkZhaW9A+SrpO0UtJ7zWzlOJf+m3NuTfbxT7lqz3TIi4T1xuVV+sX2o8pkXNDNAQAAc0Que8guk7TbOfeqc25Q0vcl3ZzDnzcjrllRraOdA9p6qCPopgAAgDkil4GsTtKBUa8bsu+N9U4z22Jm95vZwvFuZGYbzGyjmW1samrKRVun7Krl8xQy6dFtDFsCAIDpkctAZuO8N3ac7yeS6p1zqyU9Kunb493IOXeXc26dc25dVVXVNDfz5JQVxLSuvlw/394YaDsAAMDckctA1iBpdI/XAkmHRl/gnGtxzg1kX35T0iU5bM+0efOKam0/3KmGNtYkAwAApy+Xgew5ScvMbImZxSTdKunHoy8ws5pRL2+StD2H7Zk216ysliT9gl4yAAAwDXIWyJxzKUl/IOk/5YPWfc65l8zsL8zspuxld5jZS2b2gqQ7JN2eq/ZMpyWVBTq3qkCPsvwFAACYBpFc3tw597Ckh8e897lRx5+R9JlctiFXrllZrbuf2qPO/qSK49GgmwMAAM5grNR/iq5ZUa1k2unxncHO+gQAAGc+AtkpunhRmepKE/q7R3aytyUAADgtBLJTFA6ZvnzrGjW09ekzP3hRzrFyPwAAODUEstNwaX25/vDN5+mhLYf1/ecOnPgDAAAA4yCQnaaPvPFcvX5ZpT7/45e040hn0M0BAABnIALZaQqFTF969xoVxaP66D3PU08GAABOGoFsGlQV5ekr712jfS29+tR9LyiToZ4MAABMHYFsmrzu3Ep95rrz9ci2o/ra47uDbg4AADiDEMim0YeuWKK3ranV3/38ZT22g22VAADA1BDIppGZ6X+/Y7VWzC/WHd//rfa3sPk4AAA4MQLZNEvEwvrH918iOemPH6CeDAAAnBiBLAcWlufrT29YoWdebdW9z+0PujkAAGCWI5DlyHsuXajLl1bofz+8Q4fa+4JuDgAAmMUIZDliZvriO1YrnXH67INsrQQAACZGIMuhheX5+uNrl+vxnU36h8d2q7GrP+gmAQCAWSgSdAPmug+8tl6Pbj+qOx95WXc+8rLOqy7Ulcvn6eNXL1NBHl8/AAAgkOVcKGT6zu+9Ri8d6tB/7W7R068065+efFVPv9Ksu2+/VPOK4kE3EQAABMzOtNqmdevWuY0bNwbdjNPy2I5Gfex7z6ssP6Zv/96lWjqvSLsbu/SzrUckSf/fG89VNMxoMgAAZzoz2+ScW3fC6whkwXixoUMf/JfnNJhKq6ooT6809Qyfe/PKan31d9YqLxIOsIUAAOB0TTWQ0Q0TkAsXlOjBj75OK2uLVV0c11/evErPfOZqfeGmVfr5tqPa8J1N6k+mg24mAACYAfSQzULf/81+febBF7V+SYW+cdslKsmPBt0kAABwCughO4PdetkifendF+k3e1v1hr99TP/05KsaSNFbBgDAXMUsy1nq7WsXaHl1sb74sx36q//Yrm//eq/esKxKB9r6tK+lR32Daf3pDSt085q6oJsKAABOEz1ks9jK2mJ95/cu079+6DKVJmL6yQuH1NYzqAvqSlRTmtDHv79Zn33wRWrNAAA4w9FDdgZ4/bIqvX5Z1THvJdMZ3fnITv3jr17V5v3t+h9vWqrFFQVaXJGvWCSkPc09evlol/a39mr9ORVau7BUZhbQbwAAACZDUf8Z7hfbj+pT//6C2nuTw++FQ6Z05th/ritrinXb+sW6eU0tOwQAADBDWIfsLNI7mNKrTT3a19Krfa096h1Ia+m8Qi2rLtT84rh+uvWIvvvMPu040qWivIjecXGdblu/WMuqi5RKZ7TjSJdeOtShSxaXa+m8wqB/HQAA5gwCGY7hnNPz+9v03Wf26z+2HNZgOqPzqgvV0Nan3kFfg5YfC+tr77tYVy6fF3BrAQCYGwhkmFBL94D+fVODntzVpGXzirR2UamWVBbo0w+8qJ1Hu/S/3n6B3nPpouM+89KhTm073CmT9LpzK7WytljhEHVpAABMhECGk9Y9kNJH73leT7zcpLetqZWT1NDWpwOtvWrsGjju+pJEVJcsLlMsHFIqk1Eq47R2YZk+8LrFKs2PnXZ7BlJptfcmVV18Zm7A/ovtR1WSiGpdfXnQTQEABIRAhlOSTGf0uR+9pAeeb1B1cZ4WlOZrQVlCy+cXaWVtsVbWFGswndGvX2nRU7ua9UJDuyQpEgop45x2HOlSQSys29Yv1vtfu1jzi+OKZDdK7+hN6sWDHXrxYIcyzumSxWVas7BU8eixe3am0hndv6lBX/nFLh3q6Nc7L16gz15/vioK83L6ez+5q0m1pQktm1d0Wj1/yXRGf/0f2/UvT+9VPBrS/f/9dbqgrmQaWwsAOFMQyHBanHOntEzG9sOd+vrjr+ihLYc0NNEzEQ0rPxZWS8/gcddHw6ZVtSWqLY2rsjBPJYmoHtpyWHuae7RmYanWLCzVd5/Zp4K8iP7k2vP1nksXHheWDrb36ZGXjig/FlZVUZ4qC/NUmBdRNBxSLBJSYV5k0pmlB9v79Affe16/3e/DZVFeRGsWleo1S8r1+mVVuqCuZMoBrbGrXx+753k9t7dN71+/WL/YflRO0o8+drnmnaE9fQCAU0cgQ6D2NPfoVzsb1dmfUld/Ut0DaS0sT+jCuhJdUFuikJk27mvVb/a2asuBDjV29aulZ1DtvUmdP79I//Mty3X1inkyM+062qU/++FWPbunVZWFebrhwvm68aJamaR//q+9+tlLR45b5mO0aNj01otq9fuvP0craoqPOffoNr9sSDrj9Lm3rlQkZNq0r02b9rVpx5EuSVJpflRXLK3UDRfW6Krz5x3Xoyf5APvQlsP6y4e2qbM/qb9552rdvKZOWw926F3f+LWWzy/S9zesP+az7b2D2paty2vrHdT84rhqShKqLU3onKqCcX8OAODMQiDDGSmVzigcsuN655xzemTbUf3wtwf1yx2NGkhlJEnF8Yje+5pF+p3LFikcMjV1Dai5e1C9gykNpjJKpp12HOnUv29sUF8yrSuWVqqmJK7WnkE19wzqhQPtWlVbrH/4nYtVX1lwzM9s7h7Qf+1u1pO7mvX4zkY1dw+qIBbWNSur9dpzKnR+TbHOqy7UziNd+suHtun5/e1aUVOsv3vXRVpZOxL8frb1sP77d5/XlcurtKAsoT3NPXq1qUeHO/qHrwmZNDpTRkKm86qLdEFdsc6rLtKi8nwtqsjXwrJ81pEDgDMIgQxzVvdASr/YflQDyYxuWF0zpYDS3juoe57dr+8/t1+ptFNZfkzlBTFdtLBE/+NNy07YG5VKZ/TsnlY9tOWQfrr1yPBCvGaSc1JVUZ7+6C3L9c5LFow7vPm1x3frzv/cqcK8iM6pKtSSygJfl1dTrJW1xSrLj6mle0CHOvp1oLVX2w93auuhTm092KHWMUO9lYUxLSz34aw/mdaRzn4d7uhX/2Ba1SVx1ZTENa8orkjIlHFOTr6NLnuccU7O+WdJurCuRDevqdP8kpEh1b7BtLYf6VR1cVy1JXF2eQCAU0QgA3Ikk3FqaOvT9iOd2n64U/FoWO9fv/iEwbA/mVZeJHRS4cY5p46+pPa19Gp/q38cGHpu61UiGtb8koRqS+KKR8M6mg1njZ39yjgfGEPZnxcKSSZTyCQzk0lKO6d9Lb0yk153boUuqC3Rpn1teqGhXcm0/7uhKB7R+fOLVF9RoMpsjV5pIqq+ZFrdAyn1DKS0oCyh155TqYXliWN+v3TGaU9zj1461KGtBzvUM5hWVWGeqoryVFMS16VLylUcj578P4Rx9A6mFA6Z8iJn/lBvR29SkbAF0ht6qvWjAMZHIAMwJXube/Tgbw/qh5sP6mBbny5cUKLLlpRr7cIyNXcPaOeRLm0/3KmGtj619AwMB7Xx1JUmdF51oVp7k2ruGlBT94AGs8PLsXBIhfGI2noHNfTXTiRkWldfpquWz5OT9OJBH9z2t/YqZKawmSJh0/nzi/Tacyu0/pwKrVlYqqJRIW53Y5e+9dRe/eD5BsXCIb15ZbVuWF2jK5ZVKhLyS7KkM06pjFM67Z+PdPTrhYZ2bWlo196WXq1ZWKqrls/TuvoypdJOz+xp0RMvN+lIR7/ec+lCvfG8qmNCyr6WHh1o7VNVUZ7mFeWpND96WiEmmc5of2uvfrm9UT/fdlQb97UqGg7pLavm6x1r6/T6ZZXDs5VzpT+Z1pcf3aVvPfWq1i0u14Y3nqMrx/zeE2lo69WB1j5dvLh03EB8oLVX//nSET3y0lFtPdShSxaX6ZoV1bp6xTzVliSUzPjygmh4bgRqYDQCGYCT4pxTMu0Ui0z8H/6hHruOvqQS0bAK4xHFI2G90tStX7/aol+/0qJ9Lb2qKIypqihPVYV5WlZdpFW1xVo6r1DRcEjJdEatPYN+4sfLTXpsR+PwBIqhiR9LsvV86YwPCj48dQxP3qgsjGlReb6i4ZCe3dOqWCSkt6+pUyZba9jRl5zwdxitLD+qReX52na4U8m0U1FeRAPpjAZTGeVFQiqKR9TcPagVNcX6vcvr1dg1oP/YcljbDncec59IyBSLhBQNhxQNm6LhkCLZ52gopGjEFAmFFMuGKj94LPUOpnW0009oGfqr+Pz5RXrzymq19yb1ky2H1N6bVEkiqgvrSrSytlgraopUW5JQRWFMZfkxpTJOO490aeeRLu1t6VFFQUwLyvK1oDyh0kRsuJfUP0vK9pIW5kVUkh9VXiSsp19p1md/8KL2tvTqLSurtaWhQ0c6+7W8ukjXX1ijecV5wz2bVUV5qiiMKRYO6elXWvTtp/fq0e1HlXF+hvKbVszTVcvnqbl7QFsa/DI3e5p7hn+3NQtL9eye1uH3RguZdF51kVYvKNGFdSUqTkQVC4cUCfvZ0tXFeaoujo/bc9g7mNKRjn71DKRVFI+oJBFVPBrW8/vb9MTLTfrVy01KZZyuPn+e3ryyWmsXlSlkUs9gWu29gyoviCk/Rn0mph+BDMAZo7GzX9FwSGUFEy8o3D2Q0sa9rdp+uEv7W3u0t7lXrT2DumF1jd73mkXD69QNpjL6r1eatXl/u8IhUzhkiox+DodUnh/T6gUlWlDmh1i7B1J6alezfvVyk/JjYb3hvCq9Zkm5Qmb60eaD+scnXtXuxm5J0sWLSnX9hTVaVVuilp4BHe0cUEu2JzCZziiZcUqm/ELJg+mMUmnf+5NM+/OSHzqWpEQsPBwyakriet25lVpYnj/8Ow+mMvrVy016dNtRbTvcqZ1Hu4Z7HMdTmh9VZ19Sk0w6Pk4iGlZfMq3FFfn6X2+/UJcvrdRgKqOfvHBI33zy1eGwPFZ+LKzewbTKC2J672ULtXpBqX65vVGPbDuitmyNZW1JXBcuKNGl9eV6y8r5WlQx8ru90tStx3c2qbMvmQ2zps6+lLYc7NCLDe3D95iozfHoUAAOqbM/qa7+1ITXx8IhrasvUzhk+vUrLUplnApiYQ1m/9lII2Fw7aJSnT+/WEVxv1xOQSyigrywCvIiyo+Flc72sB7p7FdHX1ILy/K1dF6h6koTCk2yPE5rz6Ae29GoX+5oVGNXv+orClRfWaAFZQl19qfU3DWg5u4BLSrP19vW1h2zIPZgKqMXD7Zrd2O39rf2al9Lr2KRkK6/oEavP6/yuF7FTMZvlffQlsN6+WiXrlo+TzetqZ3WRbadc+rs8995Sf6xZQcDqbR+tbNJGed0+dLKY3q0p8tgKjP87/dsRyADgGmSyTht2t+mulK/LElQUumM9jT36GjngNp6B9XW6yd8LJtXpOXzi1ReEFMyndHh9n7tb+1V90DST+jQsZM5nPMBt73XLzVTXhjTB1+3RInY8cOFA6m0WroH1dQ1kJ3F7J9begZ1QV2Jblxdc8ykmFQ6ox1HujS/xK8teCqcczrS6Xu7UpmMkimnrv6kjnb1q7HTt2EgG4AHUhkV5UVUXRLX/OK4CvMi6upPqbM/qZ6BlFbUFGv9ORXDvWqd/Uk9vrNJG/e2Kj8WUVl+VCWJqA519GvzgXa9cKB9yj2soyWiYZXlRxUO+6F2/z8AIYVCpkzG6eXGLjknzSvKU31Fgfa29ByzA4qZ3/2kvTepkEmXL63UZfXl2rS/Tb/Z0zq853AkZKorS6ijL6n23qSK4xG96fx5KsiLaDDlv4+Ne1t1qKNfsUhIi8vztauxW2bS+iUVqiiMqaMvqc6+pMIh07J5RVpWXaj6igI1dw9ob0uv9rX0qGcwrcio/5kZ+q4HUxk1dw/ocEe/egfTMpMuqC3RFcsqddGCEj25q1kPbTk8/B1Gw6bLlpTrsvoKDab97isdfUnFwr4HujgRVXE8OnxcFI+oOB4dPm7tGdSL2Z7WnUe61NjVr6auAXX2p4a/s7L8mErz/bN/+N7RWMSvRVldnKeLFpSqvqJAoZDJOacDrX166VCH5hXHdcnislP6czpVBDIAAE6Sc05N3QPqHfCTVnoH0+oZSKln0E9gCZlpfjb8lSSi2t/aq12N3drd2K3OvuRIvaIbqVl0zumCuhJds6Jaq2qLh3vSugdSOtzep+JEVOUFMUXDIe1p7tEPnm/QD54/qIPtfTq3qkCXL63U686t1KraYtWU+N1PkumMntrdrJ+8cEhPvNws59xwAFlaVagbL6rRNSuqVRSP6pWmbv148yH9dOthJdNOxQkfQgdTae062n3Mot3RsGlheb6K41G/JV7aKZ1xw0PysUhIlYUxzS9OqLY0rt7BtJ7a3azn97UplXGKR0P6b6vm6x0XL1A8EtIvdzbql9sbtauxW+GQqTThw1YynVFXdp3KqfToJqJhnV9TpJqSuKoK81RRmKdUxqm9d1Ct2TUs23oH1dYzqPa+pPqT6ePuWxyPaEllgV5t7hnuUb3lkgW6810XTdufn/EQyAAAOENlMk6d/clp2Rf4RJq7B7SvpVfzivJUW5o4pWHA7oGUXjrYoVV1JSocp8avbzCtePT4WeaZjFPPYGq4V7Ozz4e0oeOieEQX1pXonKrCk25XKp3RYDqjA6192nygTZsPdGhvc4/OqSrQqtoSraot1vL5RTlfhHtWBDIzu1bS/5EUlvRPzrkvjjmfJ+k7ki6R1CLpPc65vZPdk0AGAADOFFMNZDmbR21mYUn/IOk6SSslvdfMVo657EOS2pxzSyX9vaS/yVV7AAAAZqtcLmxzmaTdzrlXnXODkr4v6eYx19ws6dvZ4/slXW2sSAgAAM4yuQxkdZIOjHrdkH1v3GuccylJHZIqctgmAACAWSeXgWy8nq6xBWtTuUZmtsHMNprZxqampmlpHAAAwGyRy0DWIGnhqNcLJB2a6Bozi0gqkdQ69kbOubucc+ucc+uqqqpy1FwAAIBg5DKQPSdpmZktMbOYpFsl/XjMNT+W9IHs8S2SfunOtHU4AAAATlPONu5yzv2/9u4/1uq6juP48xUkiVRISD+4TNBYiU6BXKOo5rQWmAP/wEWRsXLrH1vaaimjbPlf64fVRmoTA42pkyDvmJZ2czT/AAQCRIG8qeU1ClqKaVNB3/3x+dx1vsdzkK3u9wPn+3psZ/f7/ZzvPfd93nuf73nf7+d7zveIpC8DvyF97cWtEfGopOuBrRHRD6wEbpc0SDoytnik4jEzMzM7Xo3olVQj4l7g3rax61qWXwIuG8kYzMzMzI53IzllaWZmZmbHwA2ZmZmZWWFuyMzMzMwKc0NmZmZmVpgbMjMzM7PC3JCZmZmZFeaGzMzMzKwwN2RmZmZmhbkhMzMzMyvMDZmZmZlZYTrRruUt6SDw5xr+1ETgHzX8nROF81HlfFQ5H1XOR5XzUeV8VPV6Pk6PiNPeaKMTriGri6StEXF+6TiOF85HlfNR5XxUOR9VzkeV81HlfCSesjQzMzMrzA2ZmZmZWWFuyLr7WekAjjPOR5XzUeV8VDkfVc5HlfNR5Xzgc8jMzMzMivMRMjMzM7PC3JC1kTRP0j5Jg5KuLR1P3SRNkfSgpD2SHpV0VR6fIOkBSY/nn6eWjrVOkkZJ+oOkDXl9mqTNOR93STqpdIx1kTRe0lpJe3OdfKjJ9SHpq/m1slvSHZLe0rT6kHSrpAOSdreMdawJJT/J+9hdkmaXi3xkdMnH9/JrZpek9ZLGt9y3LOdjn6RPlol65HTKR8t9X5cUkibm9Z6vj27ckLWQNApYAcwHZgCfkTSjbFS1OwJ8LSLOAuYAV+YcXAsMRMR0YCCvN8lVwJ6W9e8CN+R8PAtcUSSqMn4M/Doi3g+cR8pLI+tD0mTgK8D5EXEOMApYTPPqYxUwr22sW03MB6bn25eAG2uKsU6reH0+HgDOiYhzgT8CywDy/nUxcHb+nZ/m96JesorX5wNJU4BPAH9pGW5CfXTkhqzqg8BgRDwREa8AdwILC8dUq4jYHxHb8/K/SG+2k0l5WJ03Ww1cWibC+knqAybjYvAAAATkSURBVD4F3JLXBVwIrM2bNCYfkt4GfAxYCRARr0TEczS4PoDRwMmSRgNjgf00rD4i4vfAP9uGu9XEQuC2SDYB4yW9u55I69EpHxFxf0QcyaubgL68vBC4MyJejogngUHSe1HP6FIfADcA3wBaT2bv+froxg1Z1WTg6Zb1oTzWSJKmArOAzcA7I2I/pKYNmFQustr9iLTTeC2vvwN4rmXn2qQ6OQM4CPw8T+HeIukUGlofEfEM8H3Sf/j7gUPANppbH6261YT3s/BF4L683Mh8SFoAPBMRO9vuamQ+wA1ZO3UYa+THUCWNA34JXB0Rz5eOpxRJlwAHImJb63CHTZtSJ6OB2cCNETELeJGGTE92ks+LWghMA94DnEKacmnXlPo4Fk1+/SBpOenUkDXDQx026+l8SBoLLAeu63R3h7GezscwN2RVQ8CUlvU+4K+FYilG0ptJzdiaiFiXh/8+fNg4/zxQKr6azQUWSHqKNIV9IemI2fg8RQXNqpMhYCgiNuf1taQGran18XHgyYg4GBGHgXXAh2lufbTqVhON3c9KWgpcAiyJ/37nVBPzcSbpn5ided/aB2yX9C6amQ/ADVm7h4Hp+RNSJ5FOtOwvHFOt8vlRK4E9EfHDlrv6gaV5eSlwT92xlRARyyKiLyKmkurhdxGxBHgQWJQ3a1I+/gY8Lel9eegi4DEaWh+kqco5ksbm185wPhpZH2261UQ/8Pn8abo5wKHhqc1eJmkecA2wICL+3XJXP7BY0hhJ00gns28pEWNdIuKRiJgUEVPzvnUImJ33L42sDwAiwreWG3Ax6RMwfwKWl46nwPP/COnw8C5gR75dTDpvagB4PP+cUDrWArm5ANiQl88g7TQHgbuBMaXjqzEPM4GtuUZ+BZza5PoAvgPsBXYDtwNjmlYfwB2kc+gOk95cr+hWE6QpqRV5H/sI6ROqxZ9DDfkYJJ0bNbxfvall++U5H/uA+aXjryMfbfc/BUxsSn10u/mb+s3MzMwK85SlmZmZWWFuyMzMzMwKc0NmZmZmVpgbMjMzM7PC3JCZmZmZFeaGzMzsGEm6QNKG0nGYWe9xQ2ZmZmZWmBsyM+s5kj4naYukHZJuljRK0guSfiBpu6QBSaflbWdK2iRpl6T1+fqUSHqvpN9K2pl/58z88OMkrZW0V9Ka/A39Zmb/EzdkZtZTJJ0FfBqYGxEzgVeBJaQLf2+PiNnARuDb+VduA66JiHNJ3ww+PL4GWBER55GuTzl8+ZZZwNXADNI38s8d8SdlZj1v9BtvYmZ2QrkI+ADwcD54dTLpwtavAXflbX4BrJP0dmB8RGzM46uBuyW9FZgcEesBIuIlgPx4WyJiKK/vAKYCD4380zKzXuaGzMx6jYDVEbGsMih9q227o1037mjTkC+3LL+K96Nm9n/gKUsz6zUDwCJJkwAkTZB0Oml/tyhv81ngoYg4BDwr6aN5/HJgY0Q8DwxJujQ/xhhJY2t9FmbWKP7Pzsx6SkQ8JumbwP2S3gQcBq4EXgTOlrQNOEQ6zwxgKXBTbrieAL6Qxy8HbpZ0fX6My2p8GmbWMIo42lF7M7PeIOmFiBhXOg4zs048ZWlmZmZWmI+QmZmZmRXmI2RmZmZmhbkhMzMzMyvMDZmZmZlZYW7IzMzMzApzQ2ZmZmZWmBsyMzMzs8L+A5kmxYqJ6S0KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.622323</td>\n",
       "      <td>0.547968</td>\n",
       "      <td>3.641576</td>\n",
       "      <td>0.006481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.769980</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>3.758228</td>\n",
       "      <td>0.009259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.541094</td>\n",
       "      <td>0.826607</td>\n",
       "      <td>3.646118</td>\n",
       "      <td>0.009259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.863080</td>\n",
       "      <td>3.654211</td>\n",
       "      <td>0.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.388339</td>\n",
       "      <td>0.875558</td>\n",
       "      <td>3.655684</td>\n",
       "      <td>0.004630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  categorical_accuracy  val_loss  val_categorical_accuracy\n",
       "0  1.622323              0.547968  3.641576                  0.006481\n",
       "1  0.769980              0.761290  3.758228                  0.009259\n",
       "2  0.541094              0.826607  3.646118                  0.009259\n",
       "3  0.432804              0.863080  3.654211                  0.004630\n",
       "4  0.388339              0.875558  3.655684                  0.004630"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_csv(\"resnet50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_generator(val_generator,steps=val_generator.samples/batch_size,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(prediction,axis=1)\n",
    "print('Confusion Matrix')\n",
    "cnf_matrix = confusion_matrix(val_generator.classes, y_pred)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.viridis):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.imshow(cm, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1e451f99c923>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"figure.figsize\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m plot_confusion_matrix(cnf_matrix, classes=list(val_generator.class_indices.keys()),\n\u001b[0;32m      4\u001b[0m                       title='Confusion matrix')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=list(val_generator.class_indices.keys()),\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
